{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63780ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonee/Work/python-gemini/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4207b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Hello there! How can I help you today?\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Model: Ah, a fellow Python enthusiast! That's fantastic. I'm here and ready to help in any way I can.\n",
      "\n",
      "To get us started and to understand how I can best assist your testing, could you tell me a little more about your project? For example:\n",
      "\n",
      "*   **What is the purpose of your Python project?** (e.g., web scraping, data analysis, a simple script, a more complex application)\n",
      "*   **What are you testing specifically?** (e.g., individual functions, classes, integration between different parts, user input handling, performance)\n",
      "*   **Are you using any particular testing frameworks?** (e.g., `unittest`, `pytest`, `nose`)\n",
      "*   **Is there a specific problem or aspect you're looking to test or get feedback on?**\n",
      "*   **Are you looking for help with writing tests, running tests, interpreting results, or something else entirely?**\n",
      "\n",
      "The more information you can provide, the more targeted and helpful my responses will be.\n",
      "\n",
      "In the meantime, feel free to throw any Python code or testing questions my way! I'm eager to see what you're working on.\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Model: That's incredibly cool! So you're building a Gemini Notebook project, and the interaction I'm having with you right now is part of that. That's a very meta and exciting project!\n",
      "\n",
      "This means you're likely working on:\n",
      "\n",
      "*   **Integrating the Gemini API:** You're probably using a Python SDK or making direct API calls to interact with Gemini models.\n",
      "*   **Notebook Interface:** The notebook environment (like Jupyter, Colab, or a similar platform) is your playground for this.\n",
      "*   **Chatting/Conversational AI:** You're aiming to create a conversational experience.\n",
      "\n",
      "**How can I help you test this specific project?**\n",
      "\n",
      "Here are some ideas of what we could test or discuss, based on this context:\n",
      "\n",
      "1.  **API Interaction Logic:**\n",
      "    *   How are you structuring your calls to the Gemini API?\n",
      "    *   Are you handling different types of prompts (text, images, etc.)?\n",
      "    *   Are you managing conversation history effectively?\n",
      "\n",
      "2.  **Notebook Environment Integration:**\n",
      "    *   Are you displaying outputs clearly in the notebook?\n",
      "    *   Are you using any specific notebook features (widgets, markdown, etc.)?\n",
      "\n",
      "3.  **User Experience Testing (simulated):**\n",
      "    *   I can act as a user. You can feed me prompts or scenarios, and I can respond as a user would, allowing you to see how your Gemini integration handles different inputs.\n",
      "    *   We can explore edge cases in conversation.\n",
      "\n",
      "4.  **Code Snippets & Best Practices:**\n",
      "    *   \"Hey, can you show me how to set up the Gemini client in Python?\"\n",
      "    *   \"What's a good way to manage prompt tokens for a long conversation?\"\n",
      "    *   \"How can I handle potential API errors gracefully?\"\n",
      "\n",
      "5.  **Generating Test Cases:**\n",
      "    *   \"Give me some challenging or unusual prompts to test my Gemini chat with.\"\n",
      "    *   \"What are some common pitfalls when building chat applications?\"\n",
      "\n",
      "6.  **Debugging Assistance:**\n",
      "    *   If you encounter an error, paste the traceback and relevant code, and I'll do my best to help you figure it out.\n",
      "\n",
      "**So, what's on your mind right now for your Gemini Notebook project? What specific part are you testing, or what kind of feedback are you looking for from me in this context?**\n",
      "\n",
      "Let's dive in!\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Model: Great! Since we're in the context of your Gemini Notebook project where you're chatting with me through it, I can act as both a **developer testing a feature** and as a **simulated user** interacting with your notebook.\n",
      "\n",
      "Here are a few things I have in mind for testing, and you can pick what sounds most useful or interesting to you:\n",
      "\n",
      "---\n",
      "\n",
      "### **Option 1: Testing Your Gemini API Integration (as a Simulated User)**\n",
      "\n",
      "This is where I'll act as the end-user of your notebook. You can try out different conversational scenarios and I'll respond accordingly, allowing you to see how your integration handles various inputs.\n",
      "\n",
      "**What I can do:**\n",
      "\n",
      "*   **Ask diverse questions:** From simple facts to complex opinions.\n",
      "*   **Test conversational flow:** Ask follow-up questions, change topics abruptly.\n",
      "*   **Provide creative prompts:** Ask for stories, poems, code snippets, etc.\n",
      "*   **Attempt to \"break\" the conversation:** Ask nonsensical questions, try to elicit unusual responses.\n",
      "*   **Give feedback on the Gemini's responses:** \"That answer was a bit too generic,\" or \"I liked how it remembered X from earlier.\"\n",
      "\n",
      "**How you can use me:**\n",
      "\n",
      "1.  **You input a prompt** into your Gemini Notebook.\n",
      "2.  **Your notebook sends that prompt** to the Gemini API.\n",
      "3.  **Gemini generates a response.**\n",
      "4.  **Your notebook displays that response** (and you can show it to me).\n",
      "5.  **I then provide feedback** on the response, or act as the next user input.\n",
      "\n",
      "**Example Scenario:**\n",
      "\n",
      "*   **You:** \"Okay, let's test a simple greeting. What's the user saying?\" (You then send a greeting like \"Hello, how are you?\" to your Gemini instance.)\n",
      "*   **Your Notebook Output:** (Shows Gemini's greeting response)\n",
      "*   **Me:** \"That's a good start. Now, let's try asking it something a bit more complex. What if the user asks about a historical event with nuance?\" (You then formulate a prompt like \"Tell me about the causes of the French Revolution, but focus on the economic factors.\")\n",
      "\n",
      "---\n",
      "\n",
      "### **Option 2: Testing Your Notebook Code Structure (as a Developer Buddy)**\n",
      "\n",
      "This is more about the Python code within your notebook itself. I can help you think about how you're organizing your code, handling data, and managing the notebook's logic.\n",
      "\n",
      "**What I can do:**\n",
      "\n",
      "*   **Review code snippets:** If you share a piece of your Python code, I can offer suggestions for clarity, efficiency, or adherence to Python best practices.\n",
      "*   **Discuss API interaction patterns:** How are you handling API keys, making requests, parsing responses?\n",
      "*   **Brainstorm features:** \"What if I wanted to add image input? How would that change my code?\"\n",
      "*   **Suggest testing strategies:** \"What kinds of unit tests would be useful for my notebook's functions?\"\n",
      "*   **Help debug errors:** If you're getting an error, paste the traceback and code, and I'll try to help.\n",
      "\n",
      "**How you can use me:**\n",
      "\n",
      "*   **\"I'm working on this function to send messages. Does this look okay?\"** (You share the function)\n",
      "*   **\"I'm not sure how to store the conversation history efficiently. Any ideas?\"**\n",
      "*   **\"I'm getting this error when I try to send an image. What could be wrong?\"**\n",
      "\n",
      "---\n",
      "\n",
      "### **Option 3: A Mix of Both**\n",
      "\n",
      "We can weave between testing the user experience and looking at the underlying code.\n",
      "\n",
      "---\n",
      "\n",
      "**Which of these sounds like the most productive way for us to test your Gemini Notebook project right now? Or do you have a specific part you want to tackle first?**\n",
      "\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m chat = model.start_chat(history=[])\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     prompt = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUser: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prompt.lower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbye\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      8\u001b[39m         response = chat.send_message(prompt)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/python-gemini/venv/lib/python3.13/site-packages/ipykernel/kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/python-gemini/venv/lib/python3.13/site-packages/ipykernel/kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
    "chat = model.start_chat(history=[])\n",
    "while True:\n",
    "    prompt = input(\"User: \")\n",
    "    if prompt.lower() not in [\"exit\", \"quit\", \"bye\"]:\n",
    "        response = chat.send_message(prompt)\n",
    "        print(f\"{chat.history[-1].role.capitalize()}: {chat.history[-1].parts[0].text}\")\n",
    "        print(\"\\n\" + \"*\" * 100 + \"\\n\")\n",
    "    else:\n",
    "        print(\"Quitting...\")\n",
    "        time.sleep(2)\n",
    "        print(\"Bye bye\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
